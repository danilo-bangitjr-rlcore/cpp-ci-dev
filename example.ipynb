{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:26:23.083731Z",
     "start_time": "2024-04-24T19:26:23.077211Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from omegaconf import  OmegaConf\n",
    "from gymnasium.spaces.utils import flatdim\n",
    "from pathlib import Path\n",
    "\n",
    "from corerl.agent.factory import init_agent\n",
    "from corerl.environment.factory import init_environment\n",
    "from corerl.state_constructor.factory import init_state_constructor\n",
    "from corerl.interaction.factory import init_interaction\n",
    "from corerl.utils.evaluator import Evaluator\n",
    "from hydra import compose, initialize\n",
    "\n",
    "import corerl.utils.freezer as fr"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_save_dir(cfg):\n",
    "    save_path = (Path(cfg.experiment.save_path) / cfg.experiment.exp_name\n",
    "                 / ('param-' + str(cfg.experiment.param)) / ('seed-' + str(cfg.experiment.seed)))\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    with open(save_path / \"config.yaml\", \"w\") as f:\n",
    "        OmegaConf.save(cfg, f)\n",
    "\n",
    "    return save_path\n",
    "\n",
    "def update_pbar(pbar, stats):\n",
    "    pbar_str = ''\n",
    "    for k, v in stats.items():\n",
    "        if isinstance(v, float):\n",
    "            pbar_str += '{key} : {val:.1f}, '.format(key=k, val=v)\n",
    "        else:\n",
    "            pbar_str += '{key} : {val} '.format(key=k, val=v)\n",
    "    pbar.set_description(pbar_str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:26:28.036092Z",
     "start_time": "2024-04-24T19:26:28.031631Z"
    }
   },
   "id": "c1802f6793856460",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"config/\"):\n",
    "    cfg = compose(config_name=\"config\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:26:34.570596Z",
     "start_time": "2024-04-24T19:26:34.433839Z"
    }
   },
   "id": "72ecc858f75d8e35",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "env = init_environment(cfg.env)\n",
    "sc = init_state_constructor(cfg.state_constructor, env) # only give part of the config file that is needed\n",
    "interaction = init_interaction(cfg.interaction, env, sc)\n",
    "action_dim = flatdim(env.action_space)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T17:17:16.676812Z",
     "start_time": "2024-04-24T17:17:16.670487Z"
    }
   },
   "id": "eb72b9582301bb0e",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "state_dim = sc.get_state_dim(state)  # gets state_dim dynamically\n",
    "agent = init_agent(cfg.agent, state_dim, action_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:27:05.193544Z",
     "start_time": "2024-04-24T19:27:05.169014Z"
    }
   },
   "id": "d9f6203e011ed3a5",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "evaluator = Evaluator(cfg.evaluator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:27:11.938040Z",
     "start_time": "2024-04-24T19:27:11.935398Z"
    }
   },
   "id": "78d78e32d61a67d2",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_episodes : 16 avg_reward : 0.9, avg_return : 0.9, avg_reward (100) : n/a avg_return (100) : n/a :   0%|          | 16/5000 [00:05<30:03,  2.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m transition \u001B[38;5;241m=\u001B[39m (state, action, reward, next_state, done, truncate)\n\u001B[1;32m      7\u001B[0m agent\u001B[38;5;241m.\u001B[39mupdate_buffer(transition)\n\u001B[0;32m----> 8\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m state \u001B[38;5;241m=\u001B[39m next_state\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# for logging\u001B[39;00m\n",
      "File \u001B[0;32m~/RL-Core/core-rl/corerl/agent/greedy_ac.py:232\u001B[0m, in \u001B[0;36mupdate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    230\u001B[0m update_infos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_actor()\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muniform_proposal:\n\u001B[0;32m--> 232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshare_batch:\n\u001B[1;32m    233\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_sampler(update_infos\u001B[38;5;241m=\u001B[39mupdate_infos)\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/RL-Core/core-rl/corerl/agent/greedy_ac.py:218\u001B[0m, in \u001B[0;36mupdate_sampler\u001B[0;34m(self, update_infos)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m update_infos \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m update_info \u001B[38;5;129;01min\u001B[39;00m update_infos:\n\u001B[0;32m--> 218\u001B[0m         sampler_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_sampler_loss(update_info)\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampler\u001B[38;5;241m.\u001B[39mupdate(sampler_loss)\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/RL-Core/core-rl/corerl/component/actor/network_actor.py:21\u001B[0m, in \u001B[0;36mNetworkActor.update\u001B[0;34m(self, loss)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate\u001B[39m(\u001B[38;5;28mself\u001B[39m, loss: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 21\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/RL-Core/core-rl/venv/lib/python3.12/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/RL-Core/core-rl/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "max_steps = cfg.experiment.max_steps\n",
    "pbar = tqdm(range(max_steps))\n",
    "for _ in pbar:\n",
    "    action = agent.get_action(state)\n",
    "    next_state, reward, done, truncate, env_info = interaction.step(action)\n",
    "    transition = (state, action, reward, next_state, done, truncate)\n",
    "    agent.update_buffer(transition)\n",
    "    agent.update()\n",
    "    state = next_state\n",
    "    \n",
    "    # for logging\n",
    "    evaluator.update(transition)\n",
    "    stats = evaluator.get_stats()\n",
    "    update_pbar(pbar, stats)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:27:48.352528Z",
     "start_time": "2024-04-24T19:27:42.532076Z"
    }
   },
   "id": "ed66983f0e0d26d6",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Freezer Demo\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c33b12f07a61c714"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "save_path = prepare_save_dir(cfg)\n",
    "fr.init_freezer(save_path / 'logs')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:28:15.103985Z",
     "start_time": "2024-04-24T19:28:15.097256Z"
    }
   },
   "id": "7f3e61bd179c6e76",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fr.freezer['Test'] = 'Something!'\n",
    "fr.freezer.save()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T19:28:24.968927Z",
     "start_time": "2024-04-24T19:28:24.966165Z"
    }
   },
   "id": "c1f59f340195079",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/5000 [00:03<28:04,  2.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m transition \u001B[38;5;241m=\u001B[39m (state, action, reward, next_state, done, truncate)\n\u001B[1;32m      7\u001B[0m agent\u001B[38;5;241m.\u001B[39mupdate_buffer(transition)\n\u001B[0;32m----> 8\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m state \u001B[38;5;241m=\u001B[39m next_state\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# freezer example\u001B[39;00m\n",
      "File \u001B[0;32m~/RL-Core/core-rl/corerl/agent/greedy_ac.py:232\u001B[0m, in \u001B[0;36mupdate\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    230\u001B[0m update_infos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_actor()\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muniform_proposal:\n\u001B[0;32m--> 232\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshare_batch:\n\u001B[1;32m    233\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_sampler(update_infos\u001B[38;5;241m=\u001B[39mupdate_infos)\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/RL-Core/core-rl/corerl/agent/greedy_ac.py:218\u001B[0m, in \u001B[0;36mupdate_sampler\u001B[0;34m(self, update_infos)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m update_infos \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m update_info \u001B[38;5;129;01min\u001B[39;00m update_infos:\n\u001B[0;32m--> 218\u001B[0m         sampler_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_sampler_loss(update_info)\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampler\u001B[38;5;241m.\u001B[39mupdate(sampler_loss)\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/RL-Core/core-rl/corerl/component/actor/network_actor.py:21\u001B[0m, in \u001B[0;36mNetworkActor.update\u001B[0;34m(self, loss)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate\u001B[39m(\u001B[38;5;28mself\u001B[39m, loss: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 21\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/RL-Core/core-rl/venv/lib/python3.12/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/RL-Core/core-rl/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "max_steps = cfg.experiment.max_steps\n",
    "pbar = tqdm(range(max_steps))\n",
    "for _ in pbar:\n",
    "    action = agent.get_action(state)\n",
    "    next_state, reward, done, truncate, env_info = interaction.step(action)\n",
    "    transition = (state, action, reward, next_state, done, truncate)\n",
    "    agent.update_buffer(transition)\n",
    "    agent.update()\n",
    "    state = next_state\n",
    "    \n",
    "    # freezer example\n",
    "    fr.freezer['transition'] = transition\n",
    "    fr.freezer.save()\n",
    "    fr.freezer.increment()\n",
    "    fr.freezer.clear()  # Optionally clearing the log"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T17:17:32.625706Z",
     "start_time": "2024-04-24T17:17:28.830552Z"
    }
   },
   "id": "de164883292337f",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ab8d6aa2ab7e02da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
