defaults:
  - gym
  - env: env/pendulum

agent:
  n_critic_updates : 1
  n_actor_updates : 1
  n_sampler_updates : 1
  num_samples: 32
  uniform_sampling_percentage: 0.8
  gamma: ${experiment.gamma}
  discrete_control: ${env.discrete_control}
  seed: ${experiment.seed}

  critic:
    buffer:
      seed: ${experiment.seed}

  actor:
    buffer:
      seed: ${experiment.seed}
    actor_optimizer:
      lr: 0.00001

experiment:
  exp_name: pendulum_test/
  load_path : null
  save_path : output
  max_steps: 10000
  online_learning : True
  debug : 0
  seed : 1
  device : cpu
  timeout : 0
  offline_steps : 0
  render : 1
  render_after : 5000
  load_env_obs_space_from_data : False
  param_from_hash : True
  gamma : 0.99
  train_split : 0.9
  plot_split : 0.999
  test_epochs : []
  offline_stat_keys: []
  online_stat_keys: []

pipeline:
  state_constructor:
    defaults: []

  agent_transition_creator:
    name: anytime
    steps_per_decision: 1
    countdown: 'null'
    gamma: ${experiment.gamma}

  tags:
  # observations
    - name: "x"
      outlier:
        name: identity
      state_constructor:
        - name: multi_trace
          trace_values: [0.95]

    - name: "y"
      outlier:
        name: identity
      state_constructor:
        - name: multi_trace
          trace_values: [0.95]

    - name: "ang_vel"
      outlier:
        name: identity
      state_constructor:
        - name: multi_trace
          trace_values: [0.95]

  # rl stuff
    - name: action
      is_action: True
      outlier:
        name: identity
      state_constructor:
        - name: normalize
          min: -2
          max: 2
          from_data: False

    - name: reward
      outlier:
        name: identity

    - name: term
      outlier:
        name: identity

    - name: trunc
      outlier:
        name: identity
      state_constructor:
        - name: 'null'
