defaults:
  - gym
  # - eval@eval.reward : reward
  - pipeline/agent_transition_creator: anytime
  - override agent: greedy_ac
  - override env : pendulum
  - override hydra/job_logging: custom
  - override agent/actor/actor_network: squashed_gaussian
  - _self_

agent:
  n_critic_updates : 1
  n_actor_updates : 1
  n_sampler_updates : 1
  num_samples: 32
  uniform_sampling_percentage: 0.8
  critic:
    critic_network:
      ensemble: 2

  actor:
    actor_optimizer:
      lr: 0.00001

experiment:
  exp_name: pendulum_test/
  load_path : null
  save_path : output
  max_steps: 10000
  online_learning : True
  debug : 0
  seed : 1
  param : 0
  device : cpu
  timeout : 0
  offline_steps : 0
  render : 1
  render_after : 5000
  load_env_obs_space_from_data : False
  param_from_hash : True
  gamma : 0.99
  train_split : 0.9
  plot_split : 0.999
  test_epochs : []
  offline_stat_keys: []
  online_stat_keys: []

pipeline:
  state_constructor:
    defaults: []

  obs_interval_minutes: 5
  agent_transition_creator:
    steps_per_decision: 1
    countdown: 'null'

  tags:
  # observations
    - name: "x"
      outlier:
        name: identity
      state_constructor:
        - name: multi_trace
          trace_values: [0.95]

    - name: "y"
      outlier:
        name: identity
      state_constructor:
        - name: multi_trace
          trace_values: [0.95]

    - name: "ang_vel"
      outlier:
        name: identity
      state_constructor:
        - name: multi_trace
          trace_values: [0.95]

  # rl stuff
    - name: action
      is_action: True
      outlier:
        name: identity
      state_constructor:
        - name: normalizer
          min: -2
          max: 2
          from_data: False

    - name: reward
      outlier:
        name: identity

    - name: term
      outlier:
        name: identity

    - name: trunc
      outlier:
        name: identity
      state_constructor:
        - name: 'null'
